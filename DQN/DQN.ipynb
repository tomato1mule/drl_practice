{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "\n",
    "import gym\n",
    "\n",
    "from replay_buffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self,N_s,N_a):\n",
    "        super().__init__()\n",
    "        self.N_s = N_s\n",
    "        self.N_a = N_a\n",
    "        \n",
    "        self.layer1 = nn.Linear(N_s,200)\n",
    "        self.layer2 = nn.Linear(200,200)\n",
    "        self.layer3 = nn.Linear(200,N_a)\n",
    "    \n",
    "    def forward(self,s):\n",
    "        Q = F.leaky_relu(self.layer1(s))\n",
    "        Q = F.leaky_relu(self.layer2(Q))\n",
    "        Q = self.layer3(Q)\n",
    "        \n",
    "        return Q\n",
    "    \n",
    "    def epsilon_greedy(self,s,eps=1e-1):\n",
    "        assert s.shape == (self.N_s,)\n",
    "        assert eps*self.N_a <= 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Q = self.forward(s)\n",
    "        \n",
    "        a = torch.argmax(Q)\n",
    "        p = [eps]*self.N_a\n",
    "        p[a] += (1 - (eps * self.N_a))\n",
    "        return np.random.choice(np.arange(N_a),p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, buffer, policy, render = False):\n",
    "    s = env.reset()\n",
    "    done = 0\n",
    "    if render:\n",
    "        env.render()\n",
    "    while(not done):\n",
    "        s_ = torch.tensor(s,dtype = torch.float32).to(device)\n",
    "        a = np.array(policy(s_))\n",
    "        ns, r, done, info = env.step(a)\n",
    "        T = [s,ns,a,r,done]\n",
    "        buffer.append(T)\n",
    "        s = ns.copy()\n",
    "        if render:\n",
    "            env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(batch,Q,NQ,discount):\n",
    "    R = batch['reward']\n",
    "    R = torch.tensor(R,dtype=torch.float32).to(device)\n",
    "    D = batch['done']\n",
    "    D = torch.tensor(D,dtype=torch.bool).to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    QA = Q[np.arange(N_batch),batch['action']]\n",
    "    Q_target = torch.max(NQ,dim=1).values\n",
    "    Q_target = R + (~D)*discount*Q_target\n",
    "    \n",
    "    return F.mse_loss(QA,Q_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_s = 4\n",
    "N_a = 2\n",
    "N_batch = 64\n",
    "tau = 0.01\n",
    "\n",
    "dqn = DQN(N_s,N_a).to(device)\n",
    "optimizer = torch.optim.Adam(dqn.parameters(),lr=1e-3)\n",
    "target_dqn = DQN(N_s,N_a).to(device)\n",
    "target_dqn.load_state_dict(dqn.state_dict())\n",
    "\n",
    "buffer = ReplayBuffer(max_len = 1e6)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "\n",
    "#run_episode(env, buffer, policy = lambda s:dqn.epsilon_greedy(s,eps=1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 132.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#Complete random action\n",
    "for episode in tqdm(range(1000)):\n",
    "    policy = lambda s:target_dqn.epsilon_greedy(s,eps=5e-1)\n",
    "    run_episode(env, buffer, policy, render = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [03:22<00:00, 14.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(3000)):\n",
    "    # Run episode\n",
    "    policy = lambda s:target_dqn.epsilon_greedy(s,eps=5e-2)\n",
    "    run_episode(env, buffer, policy, render = False)\n",
    "    \n",
    "    # sample batch\n",
    "    batch = buffer.sample(N_batch)\n",
    "    S = torch.tensor(batch['state'],dtype=torch.float32).to(device)\n",
    "    NS = torch.tensor(batch['next_state'],dtype=torch.float32).to(device)\n",
    "    Q = dqn(S)\n",
    "    with torch.no_grad():\n",
    "        NQ = target_dqn(NS)\n",
    "        \n",
    "    # optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss = get_loss(batch,Q,NQ,discount = 0.99)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print(float(loss))\n",
    "\n",
    "    # sync target network\n",
    "    for param, target_param in zip(dqn.parameters(),target_dqn.parameters()):\n",
    "        target_param.data.copy_( tau * param.data + (1-tau) * target_param.data )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:08<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(3)):\n",
    "    policy = lambda s:target_dqn.epsilon_greedy(s,eps=0.)\n",
    "    run_episode(env, buffer, policy, render = True)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
